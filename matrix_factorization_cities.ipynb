{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import essential libraries\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_path = \"/home/mahendra/data/dangal/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read all events data\n",
    "uid_events = pd.read_csv(input_path+\"uid_events/be3293dc83fa4da4b356c1c01f0cfa91_000000\", sep=chr(1), names=['uid', 'model', 'ev', 'songid', 'top_src', 'top_src_id', 'top_src_type', 'city', 'ts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>model</th>\n",
       "      <th>ev</th>\n",
       "      <th>songid</th>\n",
       "      <th>top_src</th>\n",
       "      <th>top_src_id</th>\n",
       "      <th>top_src_type</th>\n",
       "      <th>city</th>\n",
       "      <th>ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COVG+iS5EmM/rVVq+va4Go/PimSbhDZ1wscgTM48OzI=</td>\n",
       "      <td>redmi 4</td>\n",
       "      <td>home:ui::view</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>lucknow</td>\n",
       "      <td>1507094456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COVG+iS5EmM/rVVq+va4Go/PimSbhDZ1wscgTM48OzI=</td>\n",
       "      <td>redmi 4</td>\n",
       "      <td>language_select:onboarding::unclick</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>lucknow</td>\n",
       "      <td>1507094461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COVG+iS5EmM/rVVq+va4Go/PimSbhDZ1wscgTM48OzI=</td>\n",
       "      <td>redmi 4</td>\n",
       "      <td>language_select:onboarding::click</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>lucknow</td>\n",
       "      <td>1507094465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            uid    model  \\\n",
       "0  COVG+iS5EmM/rVVq+va4Go/PimSbhDZ1wscgTM48OzI=  redmi 4   \n",
       "1  COVG+iS5EmM/rVVq+va4Go/PimSbhDZ1wscgTM48OzI=  redmi 4   \n",
       "2  COVG+iS5EmM/rVVq+va4Go/PimSbhDZ1wscgTM48OzI=  redmi 4   \n",
       "\n",
       "                                    ev songid top_src top_src_id top_src_type  \\\n",
       "0                        home:ui::view     \\N      \\N         \\N           \\N   \n",
       "1  language_select:onboarding::unclick     \\N      \\N         \\N           \\N   \n",
       "2    language_select:onboarding::click     \\N      \\N         \\N           \\N   \n",
       "\n",
       "      city          ts  \n",
       "0  lucknow  1507094456  \n",
       "1  lucknow  1507094461  \n",
       "2  lucknow  1507094465  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uid_events.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20275013 entries, 0 to 20275012\n",
      "Data columns (total 9 columns):\n",
      "uid             object\n",
      "model           object\n",
      "ev              object\n",
      "songid          object\n",
      "top_src         object\n",
      "top_src_id      object\n",
      "top_src_type    object\n",
      "city            object\n",
      "ts              int64\n",
      "dtypes: int64(1), object(8)\n",
      "memory usage: 1.4+ GB\n"
     ]
    }
   ],
   "source": [
    "uid_events.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to prepare data for matrix factorization we will be getting count for each pair of (uid,city). This can be done by simply doing group by on these two columns and then convert to sparse matrix through pivot tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uid                                           city      \n",
      "++6hguLjcB3jtJhQWvIL0X4n29dJkmlqdfOpeJ7MCL8=  ranchi         285\n",
      "++TCdWzyV4m4OkSkmQgGSF/jwEX3cBBq+D+oRAzRSq8=  pitampura     1347\n",
      "++fTW0762GVu9KcW49AvOmgUmLxE1kg8UzytJ193ALI=  bara bazar      23\n",
      "                                              barakpur       297\n",
      "                                              garui          468\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "uid_city_grp = uid_events.groupby(['uid','city'])\n",
    "print uid_city_grp.size()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30230 entries, 0 to 30229\n",
      "Data columns (total 3 columns):\n",
      "uid      30230 non-null object\n",
      "city     30230 non-null object\n",
      "count    30230 non-null int64\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 708.6+ KB\n",
      "None\n",
      "                                            uid        city  count\n",
      "0  ++6hguLjcB3jtJhQWvIL0X4n29dJkmlqdfOpeJ7MCL8=      ranchi    285\n",
      "1  ++TCdWzyV4m4OkSkmQgGSF/jwEX3cBBq+D+oRAzRSq8=   pitampura   1347\n",
      "2  ++fTW0762GVu9KcW49AvOmgUmLxE1kg8UzytJ193ALI=  bara bazar     23\n"
     ]
    }
   ],
   "source": [
    "uid_city_grp = uid_city_grp.size()\n",
    "uid_city_grp = uid_city_grp.reset_index(inplace=False)\n",
    "uid_city_grp.columns = ['uid', 'city', 'count']\n",
    "print(uid_city_grp.info())\n",
    "print(uid_city_grp.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# optional to save uid_city_count\n",
    "uid_city_grp.to_csv('/home/mahendra/data/dangal/feat/uid_city_count', sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import implicit library to do matrix factorization on local machine, if the data is bigger like having more than 50K unique uids or cities then its better to do it in spark. You can have a look at this example : https://spark.apache.org/docs/2.2.0/mllib-collaborative-filtering.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30230 entries, 0 to 30229\n",
      "Data columns (total 3 columns):\n",
      "uid      30230 non-null object\n",
      "city     30230 non-null object\n",
      "count    30230 non-null int64\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 708.6+ KB\n",
      "None\n",
      "                                            uid        city  count\n",
      "0  ++6hguLjcB3jtJhQWvIL0X4n29dJkmlqdfOpeJ7MCL8=      ranchi    285\n",
      "1  ++TCdWzyV4m4OkSkmQgGSF/jwEX3cBBq+D+oRAzRSq8=   pitampura   1347\n",
      "2  ++fTW0762GVu9KcW49AvOmgUmLxE1kg8UzytJ193ALI=  bara bazar     23\n",
      "uid      9997\n",
      "city     2380\n",
      "count    3764\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(uid_city_grp.info())\n",
    "print(uid_city_grp.head(3))\n",
    "print(uid_city_grp.apply(lambda x: x.nunique(), axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ we have 9997 unique uids and 2380 unique cities. Now lets use pivot_table to convert in into sparse matrix form, where every row will correspond to an uid and cities will represented by columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city                                           uid   \\N  abdullapur  abhaneri  \\\n",
      "0     ++6hguLjcB3jtJhQWvIL0X4n29dJkmlqdfOpeJ7MCL8=  0.0         0.0       0.0   \n",
      "1     ++TCdWzyV4m4OkSkmQgGSF/jwEX3cBBq+D+oRAzRSq8=  0.0         0.0       0.0   \n",
      "2     ++fTW0762GVu9KcW49AvOmgUmLxE1kg8UzytJ193ALI=  0.0         0.0       0.0   \n",
      "\n",
      "city  abhayapuri  abohar  abu  abu road  achalpur  achhnera  ...   yarada  \\\n",
      "0            0.0     0.0  0.0       0.0       0.0       0.0  ...      0.0   \n",
      "1            0.0     0.0  0.0       0.0       0.0       0.0  ...      0.0   \n",
      "2            0.0     0.0  0.0       0.0       0.0       0.0  ...      0.0   \n",
      "\n",
      "city  yaval  yavatmal  yelahanka  yelandur  yeola  zahirabad  zaidpur  \\\n",
      "0       0.0       0.0        0.0       0.0    0.0        0.0      0.0   \n",
      "1       0.0       0.0        0.0       0.0    0.0        0.0      0.0   \n",
      "2       0.0       0.0        0.0       0.0    0.0        0.0      0.0   \n",
      "\n",
      "city  zamania  zira  \n",
      "0         0.0   0.0  \n",
      "1         0.0   0.0  \n",
      "2         0.0   0.0  \n",
      "\n",
      "[3 rows x 2381 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9997 entries, 0 to 9996\n",
      "Columns: 2381 entries, uid to zira\n",
      "dtypes: float64(2380), object(1)\n",
      "memory usage: 181.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "uid_city_table = pd.pivot_table(uid_city_grp, values='count', index=['uid'], columns=['city'], aggfunc=np.sum)\n",
    "uid_city_table.fillna(0, inplace=True)\n",
    "uid_city_table.reset_index(inplace=True)\n",
    "print uid_city_table.head(3)\n",
    "print uid_city_table.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets remove uid column and convert this to matrix. Quoting directly from implicit's documentation :\n",
    "\"Parameters:\titem_users (csr_matrix) â€“ Matrix of confidences for the liked items. This matrix should be a csr_matrix where the rows of the matrix are the item, the columns are the users that liked that item, and the value is the confidence that the user liked the item.\"\n",
    "Because imlicit's als version accepts items (i.e. cities in our case) to be represented in rows and users in columns, we will be taking transpose to do this. \n",
    "\n",
    "Note that spark's als version expects just opposite of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# these are the matrix values we will be feeding to als\n",
    "print uid_city_table[uid_city_table.columns.difference(['uid'])].values.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets get a csr matrix out of those values\n",
    "uid_city_matrix = scipy.sparse.csr_matrix(uid_city_table[uid_city_table.columns.difference(['uid'])].values.transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like spark's als version in implicit also we need to give user and item identifiers as integer values, hence we \n",
    "will keep a map uids and there integer IDs, similarly for cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uid_index_map = dict([(x[0],x[1]) for x in zip(uid_city_table['uid'], range(0, 9997)) ])\n",
    "index_uid_map = dict([(x[1],x[0]) for x in zip(uid_city_table['uid'], range(0, 9997)) ])\n",
    "\n",
    "item_index_map = dict([(x[0],x[1]) for x in zip(list(uid_city_table.columns[1:]), range(0, len(list(uid_city_table.columns[1:])))) ])\n",
    "index_item_map = dict([(x[1],x[0]) for x in zip(list(uid_city_table.columns[1:]), range(0, len(list(uid_city_table.columns[1:])))) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1520\n",
      "mumbai\n",
      "606\n"
     ]
    }
   ],
   "source": [
    "# this how those map looks like\n",
    "print uid_index_map['++fTW0762GVu9KcW49AvOmgUmLxE1kg8UzytJ193ALI=']\n",
    "print item_index_map['mumbai']\n",
    "print index_item_map[1520]\n",
    "print item_index_map['delhi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:OpenBLAS detected. Its highly recommend to set the environment variable 'export OPENBLAS_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    }
   ],
   "source": [
    "# initialize a model\n",
    "# do read the documentation of implicit.als.AlternatingLeastSquares at \n",
    "# http://implicit.readthedocs.io/en/latest/als.html\n",
    "alsmodel = implicit.als.AlternatingLeastSquares(factors=50, regularization=0.05, iterations=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "alsmodel.fit(uid_city_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1520, 0.99999999999999989),\n",
       " (2319, 0.75685800295630901),\n",
       " (309, 0.66043981345789304),\n",
       " (2209, 0.59776114966578076),\n",
       " (1838, 0.47796748013709783),\n",
       " (569, 0.44503563569664439),\n",
       " (1821, 0.44149123323093686),\n",
       " (429, 0.43729040672992597),\n",
       " (2268, 0.4137829723414711),\n",
       " (0, 0.32797630525406302)]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets get similar cities to mumbai\n",
    "alsmodel.similar_items(1520, N=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mumbai',\n",
       " 'vashi',\n",
       " 'belapur',\n",
       " 'thane',\n",
       " 'pune',\n",
       " 'dahihanda',\n",
       " 'powai',\n",
       " 'borivli',\n",
       " 'udgir',\n",
       " '\\\\N',\n",
       " 'ahmedabad',\n",
       " 'ghatkopar',\n",
       " 'seohara',\n",
       " 'malad',\n",
       " 'uran',\n",
       " 'diglur',\n",
       " 'bengaluru',\n",
       " 'chandkheda',\n",
       " 'chandigarh',\n",
       " 'navi mumbai']"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[index_item_map.get(x[0], '') for x in alsmodel.similar_items(1520, N=20)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First few similar items looks good, but we are getting some outliers too like ahemdabad, bengaluru, chandigarh. So, now question is how do you evaluate what parameters for your als model to choose. That is you need to estimate best parameters for factors and regularization. You may alter number of iteration but it doesn't impact end results much because ALS is known for faster convergence within 20 iterations. For model evaluation, you need to decide a metric on which you can compare two models.\n",
    "\n",
    "One approach that is mostly used in recommender systems is to use mean percentile ranking. Read this paper (http://yifanhu.net/PUB/cf.pdf) which describes about both ALS and evaluation technique using mean percentile ranking. Try to implement that yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just using another set of params which i found would work better for this data is below :\n",
    "factors=15, regularization=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:OpenBLAS detected. Its highly recommend to set the environment variable 'export OPENBLAS_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    }
   ],
   "source": [
    "alsmodel = implicit.als.AlternatingLeastSquares(factors=15, regularization=0.3, iterations=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alsmodel.fit(uid_city_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1520, 1.0),\n",
       " (2319, 0.93941511097203689),\n",
       " (309, 0.93473712919597118),\n",
       " (2268, 0.8750816822050268),\n",
       " (2289, 0.73616872115281207),\n",
       " (2209, 0.68031698291390208),\n",
       " (569, 0.67033938313414998),\n",
       " (1382, 0.66956665040985186),\n",
       " (99, 0.64465364049714213),\n",
       " (1838, 0.54987020235025019)]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets get similar cities to mumbai\n",
    "alsmodel.similar_items(1520, N=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mumbai',\n",
       " 'vashi',\n",
       " 'belapur',\n",
       " 'udgir',\n",
       " 'uran',\n",
       " 'thane',\n",
       " 'dahihanda',\n",
       " 'malad',\n",
       " 'andheri',\n",
       " 'pune',\n",
       " 'borivli',\n",
       " 'powai',\n",
       " 'seohara',\n",
       " 'bhandup',\n",
       " 'matheran',\n",
       " 'shahpura',\n",
       " 'gevrai',\n",
       " 'chandigarh',\n",
       " '\\\\N',\n",
       " 'jiran']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[index_item_map.get(x[0], '') for x in alsmodel.similar_items(1520, N=20)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can see that above results looks much better with parameter tuning. You can use item_factors method to get vector for every city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
